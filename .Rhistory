convert_time <- function(time_minutes) {
# Calculate hours and minutes from total minutes
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
# Create time strings, ensuring two-digit formatting
time_str <- sprintf("%02d:%02d", hours, minutes)
# Return formatted string
time_str
}
# Example times provided
times <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Apply the conversion function
formatted_times <- sapply(times, convert_time)
# Print formatted times
formatted_times
library(dplyr)
library(tidyr)
# Sample data frame similar to what you might be working with
df <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Function to convert minutes since midnight to HH:MM format
convert_time <- function(time_minutes) {
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
sprintf("%02d:%02d", hours, minutes)
}
# Apply conversion within a Tidyverse pipeline
df <- df %>%
mutate(departure_time = convert_time(departure_time))
library(dplyr)
library(tidyr)
# Sample data frame similar to what you might be working with
df <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Function to convert minutes since midnight to HH:MM format
convert_time <- function(time_minutes) {
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
sprintf("%02d:%02d", hours, minutes)
}
# Apply conversion within a Tidyverse pipeline
df <- df %>%
mutate(departure_time = convert_time(hour))
library(dplyr)
library(tidyr)
# Sample data frame similar to what you might be working with
df <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Function to convert minutes since midnight to HH:MM format
convert_time <- function(time_minutes) {
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
sprintf("%02d:%02d", hours, minutes)
}
# Apply conversion within a Tidyverse pipeline
df <- df %>%
mutate(hour = convert_time(departure_time))
library(dplyr)
library(tidyr)
# Sample data frame similar to what you might be working with
df <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Function to convert minutes since midnight to HH:MM format
convert_time <- function(time_minutes) {
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
sprintf("%02d:%02d", hours, minutes)
}
# Apply conversion within a Tidyverse pipeline
df <- df %>%
mutate(hour = convert_time(hour))
# Function to convert time from integer to "HH:MM" format
convert_time <- function(time_minutes) {
# Calculate hours and minutes from total minutes
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
# Create time strings, ensuring two-digit formatting
time_str <- sprintf("%02d:%02d", hours, minutes)
# Return formatted string
time_str
}
# Example times provided
times <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Apply the conversion function
formatted_times <- sapply(times, convert_time)
# Print formatted times
formatted_times
library(tidyverse)
library(mdsr)
library(nycflights13)
SF <- flights |>
filter(dest == "SFO", !is.na(arr_delay))
convert_time <- function(time_minutes) {
# Calculate hours and minutes from total minutes
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
# Create time strings, ensuring two-digit formatting
time_str <- sprintf("%02d:%02d", hours, minutes)
# Return formatted string
time_str
}
# Times provided
times <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Apply the conversion function
formatted_times <- sapply(times, convert_time)
# Print formatted times
formatted_times
predictedgpa <- function(x) {
2.84 + 0.04*x/100
}
predictedgpa(970)
# 4 = 2.84 + 0.04*x/100
((4-2.84)/0.04)*100
# residual = true-value - predicted_value
3.71- predictedgpa(0)
# Sample Data
set.seed(123)
study_hours <- runif(100, 0, 10)  # Randomly generate study hours between 0 and 10
test_scores <- 50 + 5 * study_hours + rnorm(100, mean=0, sd=5)  # Generate test scores
# Fit Linear Regression Model
model <- lm(test_scores ~ study_hours)
summary(model)
# Sample Data
set.seed(123)
study_hours <- runif(100, 0, 10)  # Randomly generate study hours between 0 and 10
test_scores <- 50 + 5 * study_hours + rnorm(100, mean=0, sd=5)  # Generate test scores
# Fit Linear Regression Model
model <- lm(test_scores ~ study_hours)
summary(model)
study_hours
tets_scores
test_scores
View(SF)
library(tidyverse)
library(mdsr)
library(nycflights13)
SF <- flights |>
filter(dest == "SFO", !is.na(arr_delay))
convert_time <- function(time_minutes) {
# Calculate hours and minutes from total minutes
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
# Create time strings, ensuring two-digit formatting
time_str <- sprintf("%02d:%02d", hours, minutes)
# Return formatted string
time_str
}
# Times provided
times <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Apply the conversion function
formatted_times <- sapply(times, convert_time)
# Print formatted times
formatted_times
SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
library(tidyverse)
library(mdsr)
library(nycflights13)
SF <- flights |>
filter(dest == "SFO", !is.na(arr_delay))
convert_time <- function(time_minutes) {
# Calculate hours and minutes from total minutes
hours <- time_minutes %/% 60
minutes <- time_minutes %% 60
# Create time strings, ensuring two-digit formatting
time_str <- sprintf("%02d:%02d", hours, minutes)
# Return formatted string
time_str
}
# Times provided
times <- SF |>
group_by(hour) |>
count() |>
pivot_wider(names_from = hour, values_from = n) |>
data.frame()
# Apply the conversion function
formatted_times <- sapply(times, convert_time)
# Print formatted times
formatted_times
SF |>
ggplot(aes(x = hour, y = arr_delay)) +
geom_boxplot(alpha = 0.1, aes(group = hour)) +
geom_smooth(method = "lm") +
xlab("Scheduled hour of departure") +
ylab("Arrival delay (minutes)") +
coord_cartesian(ylim = c(-30, 120))
mod1 <- lm(arr_delay ~ hour, data = SF)
broom::tidy(mod1)
summary(mod1)
library(lubridate)
SF <- SF |>
mutate(
day = as.Date(time_hour),
dow = as.character(wday(day, label = TRUE)),
season = ifelse(month %in% 6:7, "summer", "other month")
)
mod2 <- lm(arr_delay ~ hour + origin + carrier + season + dow, data = SF)
broom::tidy(mod2)
summary(mod2)
# required libraries
library(here)
library(fst)
library(tidyverse)
# get the data
motor_insurance <-read.csv(here("data", "SwedishMotorInsurance.csv"))
View(motor_insurance)
cor(motor_insurance$Claims, motor_insurance$Payment)
plot( motor_insurance$Claims, motor_insurance$Payment)
reg <- lm(Payment~Claims, data = motor_insurance)
plot( motor_insurance$Claims, motor_insurance$Payment)
abline(reg = reg, col="red")
summary(reg)
wr <- read.csv(here("data", "worldrecord.csv"))
# use table function for how many question
table(wr$Event)
# or you can use count function in plyr package for better list
plyr::count(unique(wr$Event)) # instead of calling the packeag library(plyr) we used plyr::
wr[wr$Athlete== "Usain Bolt",]
wr[wr$Event=="Womens Mile",]
# create a subset of mens shotput event
mensshotput <- wr[wr$Event=="Mens Shotput",]
# plot distance and year
plot(mensshotput$Record, mensshotput$Year)
# create a subset of womens shotput event
womensshotput <- wr[wr$Event=="Womens Shotput",]
# plot distance and year
plot(womensshotput$Record, womensshotput$Year)
lm_mdl_men <- lm(Record~Year, data = mensshotput)
summary(lm_mdl_men)
# since year doesn't start with 0, recode
mensshotput$Year <- mensshotput$Year - min(mensshotput$Year)
lm_mdl_men <- lm(Record~Year, data = mensshotput)
summary(lm_mdl_men)
# In the model, We will be able to report the average rate of change in world record shotput distance per year.
# the model now simply says that with an interceot of 17.90 every additional year effect the record 0.13 meter.
# plot distance and year
plot(mensshotput$Record, mensshotput$Year)
# plot distance and year
plot(womensshotput$Record, womensshotput$Year)
lm_mdl_women <- lm(Record~Year, data = womensshotput)
summary(lm_mdl_women)
# since year doesn't start with 0, recode
womensshotput$Year <- womensshotput$Year - min(womensshotput$Year)
lm_mdl_women <- lm(Record~Year, data = womensshotput)
summary(lm_mdl_women)
# required libraries
library(here)
library(fst)
library(tidyverse)
# get the data
motor_insurance <-read.csv(here("data", "SwedishMotorInsurance.csv"))
plot( motor_insurance$Claims, motor_insurance$Payment)
summary(reg)
wr <- read.csv(here("data", "worldrecord.csv"))
wr[wr$Athlete== "Usain Bolt",]
lm_mdl_men <- lm(Record~Year, data = mensshotput)
summary(lm_mdl_men)
mensshotput$Year <- mensshotput$Year - min(mensshotput$Year)
lm_mdl_men <- lm(Record~Year, data = mensshotput)
summary(lm_mdl_men)
lm_mdl_women <- lm(Record~Year, data = womensshotput)
summary(lm_mdl_women)
# since year doesn't start with 0, recode
womensshotput$Year <- womensshotput$Year - min(womensshotput$Year)
lm_mdl_women <- lm(Record~Year, data = womensshotput)
summary(lm_mdl_women)
fish <- read.csv(here("data", "Fish.csv"))
str(fish)
View(fish)
species <-c("Bream", "Perch", "Pike", "Roach")
fish <- fish[fish$Species==species,]
barplot(table(fish$Species))
ggplot(data = fish, aes(x=Weight)) +
geom_histogram( bins = 9) +
facet_wrap(~Species)
lm(formula = Weight~Species, data = fish)
# with no intercept
lm(formula = Weight ~Species+0, data = fish)
taiwan_real_estate <- read.fst(here("data", "taiwan_real_estate.fst"))
str(taiwan_real_estate)
View(taiwan_real_estate)
ggplot(data = taiwan_real_estate, aes(x=n_convenience, y= price_twd_msq))+
geom_point(alpha=0.5)+
geom_smooth(method="lm", se=FALSE) +
scale_x_continuous("No. of convenience stores ÅŸn walking distance")+
scale_y_continuous("House price per unit area in Taiqan dollars per square meter")+
ggtitle("Taiwan Real Estate Price: Conveniency effects on Prices")+
theme_bw()
taiwan_model <- lm(price_twd_msq~n_convenience, data = taiwan_real_estate)
plot(price_twd_msq~n_convenience, data = taiwan_real_estate)
abline(reg = taiwan_model, col="red")
summary(taiwan_model)
group1 <-taiwan_real_estate[taiwan_real_estate$house_age_years=="0 to 15",]
mean(group1$price_twd_msq, na.rm=TRUE)
group2 <-taiwan_real_estate[taiwan_real_estate$house_age_years=="15 to 30",]
mean(group2$price_twd_msq, na.rm=TRUE)
group3 <-taiwan_real_estate[taiwan_real_estate$house_age_years=="30 to 45",]
mean(group3$price_twd_msq, na.rm=TRUE)
taiwan_real_estate |>
group_by(house_age_years) |>
summarise(mean_by_group =mean(price_twd_msq))
mdl_price_vs_age <- lm( price_twd_msq ~ house_age_years+0, data = taiwan_real_estate)
summary(mdl_price_vs_age)
# Let's recall IQ score data we have cretaed
# Point Estimation
mean_est <- mean(IQ) # Mean IQ score
# Lets make fake IQ scores
set.seed(178)
IQ <- rnorm(n=1000, mean=100, sd=15) # generate IQ scores
IQ <- round(IQ) # IQs are whole numbers
summary(IQ)
# Load necessary library
if(!require(ggplot2)) install.packages("ggplot2", dependencies=TRUE)
library(ggplot2)
# Define the parameters
mean <- 100
sd <- 15
n <- 30
value <- 110
# Calculate z-score
z <- (value - mean) / (sd / sqrt(n))
# Create data for the plot
x <- seq(70, 130, length.out=300)
y <- dnorm(x, mean=mean, sd=sd/sqrt(n))
# Create the plot
ggplot(data=NULL, aes(x=x)) +
geom_line(aes(y=y), color="blue") +  # Normal distribution curve
geom_area(aes(y=ifelse(x <= value, y, 0)), fill="skyblue") +  # Shaded area for probability
geom_vline(xintercept=value, linetype="dashed", color="red") +  # Line at x = 110
labs(title="Standard Normal Distribution",
subtitle=sprintf("Shaded Area: P(X < %s) for n=%s, mean=%s, sd=%s", value, n, mean, sd),
x="X values",
y="Density") +
theme_minimal() +
annotate("text", x=value, y=0, label=sprintf("z = %.2f", z), vjust=-1, color="red")  # Label the z-score
# Print the z-score and probability less than 110
cat("Z-Score:", z, "\n")
prob <- pnorm(z)  # Probability calculation using the z-score
cat("The probability that the sample mean < 110 is:", prob, "\n")
# Calculate the probability that a standard normal random variable is greater than z
prob <- 1 - pnorm(z)
# Print the result
print(paste("The probability that a standard normal random variable is greater than", z, "is:", prob))
# Load necessary library
if(!require(ggplot2)) install.packages("ggplot2", dependencies=TRUE)
library(ggplot2)
# Define the parameters
mean <- 100
sd <- 15
n <- 30
value <- 110
# Calculate z-score
z <- (value - mean) / (sd / sqrt(n))
# Create data for the plot
x <- seq(70, 130, length.out=300)
y <- dnorm(x, mean=mean, sd=sd/sqrt(n))
# Create the plot
ggplot(data=NULL, aes(x=x)) +
geom_line(aes(y=y), color="blue") +  # Normal distribution curve
geom_area(aes(y=ifelse(x >= value, y, 0)), fill="orange") +  # Shaded area for probability greater than 110
geom_vline(xintercept=value, linetype="dashed", color="red") +  # Line at x = 110
labs(title="Standard Normal Distribution",
subtitle=sprintf("Shaded Area: P(X > %s) for n=%s, mean=%s, sd=%s", value, n, mean, sd),
x="X values",
y="Density") +
theme_minimal() +
annotate("text", x=value+5, y=0.01, label=sprintf("z = %.2f", z), vjust=-1, color="red")  # Label the z-score
# Print the z-score and probability greater than 110
cat("Z-Score:", z, "\n")
prob <- 1 - pnorm(z)  # Probability calculation for greater than using the z-score
cat("The probability that the sample mean > 110 is:", prob, "\n")
# Load necessary libraries
library(tidyverse)
library(readr)
library(knitr)
# Load course schedule CSV
course_schedule <- read_csv("~/Desktop/mac_projects 2/data-science-with-R/Course_Schedule.csv")
# Display the schedule as a formatted table
kable(course_schedule)
# Load necessary libraries
library(tidyverse)
library(readr)
library(knitr)
# Load course schedule CSV
course_schedule <- read_csv("~/Desktop/mac_projects 2/data-science-with-R/Course_Schedule.csv")
# Display the schedule as a formatted table
kable(course_schedule)
# Load necessary libraries
library(tidyverse)
library(readr)
library(knitr)
# Load course schedule CSV
course_schedule <- read_csv("~/Desktop/mac_projects 2/data-science-with-R/syllabus/Course_Schedule.csv")
# Display the schedule as a formatted table
kable(course_schedule)
# Display the schedule as a formatted table
kable(course_schedule)
# loaded packages
library(here)
library(tidyverse)
library(ggplot2)
library(mdsr)
here <- here::here()
dpath <- "data"
# read csv file
mydata <- read.csv("~/Library/CloudStorage/OneDrive-marmara.edu.tr/mac_projects 2/R_lecture/data/cars.csv")
# read csv file
mydata <- read.csv("~/Desktop/mac_projects 2/data-science-with-R/data/cars.csv")
# write csv
write.csv(mydata, file =
"~/Desktop/mac_projects 2/data-science-with-R/data/mydata.csv")
# read csv file
mydata <- read.csv("~/Desktop/mac_projects 2/data-science-with-R/data/cars.csv")
View(mydata)
# write csv
write.csv(mydata, file =
"~/Desktop/mac_projects 2/data-science-with-R/data/mydata.csv")
# read csv-file from net
mydata <- read.csv(
"https://gist.githubusercontent.com/MorganZhang100/0c489d1f376a04d5436a/raw/7c335ebe48e5751f1334bb6e4502254e3c1d1c55/cars.csv")
View(mydata)
# read excel
library(readxl)
mydata1 <- read_excel(
"~/Desktop/mac_projects 2/data-science-with-R/data/datacom.xlsx")
View(mydata1)
time_tr <- as.date(01-02-2025)
time_tr <- as.Date(01-02-2025)
time_tr <- as.Date(01-02-2025)
typeof(TRUE)
#> [1] "logical"
typeof(10L)
#> [1] "integer"
typeof(10)
#> [1] "double"
typeof("oops")
#> [1] "character"
mode(TRUE)
#> [1] "logical"
mode(10L)
#> [1] "numeric"
mode(10)
#> [1] "numeric"
mode("oops")
#> [1] "character"
typeof(TRUE)
#> [1] "logical"
typeof(10L)
#> [1] "integer"
typeof(10)
#> [1] "double"
typeof("oops")
#> [1] "character"
typeof(date_tr)
typeof(TRUE)
#> [1] "logical"
typeof(10L)
#> [1] "integer"
typeof(10)
#> [1] "double"
typeof("oops")
#> [1] "character"
typeof(time_tr)
#> [1] "character"
mode(TRUE)
#> [1] "logical"
mode(10L)
#> [1] "numeric"
mode(10)
#> [1] "numeric"
mode("oops")
#> [1] "character"
# Assign a missing value:
ms <- NA
ms
#> [1] NA
# Data type?
typeof(ms)
#> [1] "logical"
mode(ms)
#> [1] "logical"
