---
title: "Inferenatial Statistics: Regression"
author: "Hakan Mehmetcik"
format: pdf
editor: visual
execute: 
  echo: true
  warning: true
  output: asis
df-print: kable
---

# Functions and Models

## Functions

A function: You take some kind of input and you get some kind of output!

The hint here is that you can get ONE specific output from any specific input.

Ex: **A national park contains foxes that prey on rabbits.  The table below gives the two populations, F and R, over an 11-month period, where t=0 means January, t=1 means February, and so on.**

Sure, here is the table in R markdown format:

| Month | Rabbits | Foxes |
|-------|---------|-------|
| 0     | 1,000   | 150   |
| 1     | 750     | 143   |
| 2     | 567     | 125   |
| 3     | 500     | 100   |
| 4     | 567     | 75    |
| 5     | 750     | 57    |
| 6     | 1,000   | 50    |
| 7     | 1,250   | 57    |
| 8     | 1,433   | 75    |
| 9     | 1,500   | 100   |
| 10    | 1,433   | 125   |

This table shows the number of rabbits and foxes over a period of 10 months. The 'Rabbits' and 'Foxes' columns represent the population of each species at the end of each month.

1.  Is F a function of t?

Yes, because for each value of t, there is axactly one value of F.

2.  Is R a function of F? 

No, beacuse when F=57 R=750 or R=1250.

💡 A function is generally denoted by f(x) where x is the input. For example, in the function f(x) = x\^2, the function f(x) takes the value of "x" and then squares it!

👋 In statistics, **a distribution is a function that shows the possible values for a variable and how often they occur**. It's a description of the relative numbers of times each possible outcome will occur in a number of trials. Distributions can be represented in various ways, such as with graphs or probability tables.

# Simple Linear Regression

## What is regression?

Statistical models to explore the relationship a response (dependent) and explanatory (independent variable)

With regression, you can predict the values of the response variable with the use of given values of explanatory variable.

👋 Make sure that you know the followings!

**linear regression :** when the response variable is numeric

**logistic regression:** when the response variable is logical (True -false)

**simple linear/logistic regression:** when there is one explanatory variable

**multiple linear/logistic regression:** when there is more than one explanatory variable

💡 Here is a a list of possible linear relations:

![](images/clipboard-832738691.png)

👋 **lm() function to simulate linear models in R:**

In R, linear models are typically fitted using the `lm()` function. This function fits a linear model to data by finding the line of best fit that minimizes the total error of the model.

Here's an example of how you might use it:

```{r}
# Create some data
x <- c(1, 2, 3, 4, 5)
y <- c(2, 3, 5, 7, 11)

# Fit a linear model
model <- lm(y ~ x)

# Print the model summary
summary(model)
```

In this code, `lm(y ~ x)` fits a linear model to the data with `y` as the response variable and `x` as the predictor variable. The `summary(model)` function then prints a summary of the model, including the coefficients, residuals, and other diagnostic measures.

⚠️ The **`summary()`** function provides a lot of information. Here's what some of it means:

-   **Call**: This shows the function call that you used to fit the model. (`lm(y ~ x) in the example above)`

-   **Residuals**: This section provides summary statistics for the residuals, which are a measure of how far off our model's predictions are for each point.

-   **Coefficients**: This is one of the most important parts of the output. It gives the coefficients of the model, the standard error of these coefficients, and the t-value and p-value of the hypothesis test that the coefficient is different from 0. The "Estimate" column gives the coefficients of the intercept and the predictor variable(s). In this case, the coefficient for **`x`** is the slope of the line of best fit.

-   **Residual standard error**: This is the standard deviation of the residuals. It gives a measure of how wrong our model's predictions are likely to be.

-   **Multiple R-squared**: This is the proportion of variance in the response variable that can be explained by the predictor variables. It provides a measure of how well the model fits the data.

-   **F-statistic and p-value**: The F-statistic is a measure of how much better the model fits the data than a model that has no predictor variables. The p-value associated with this F-statistic is the probability of observing such an F-statistic, or one more extreme, under the null hypothesis that the model with no predictor variables fits the data as well as our model.

## Exercise 1:

For this exercise, we have bivariate data on a group of college students: the total amount (in dollars) spent on textbooks throughout their college career, and their GPA. The following linear regression model was used to predict GPA from number of dollars (in hundreds) spent:

**Predicted GPA = 2.84 + .04\*Dollars**

### Question 1:

What is the predicted GPA of a student who spent a total of \$970 on textbooks in college?

```{r}
predictedgpa <- function(x) {
  2.84 + 0.04*x/100
}

predictedgpa(970)
```

### Question 2:

If a student spent \$0 on textbooks in college and graduated with a GPA of 3.71, what is her residual? 

```{r}
# residual = true-value - predicted_value 

3.71- predictedgpa(0)
```

### Question 3:

If a student spent \$1,450 on textbooks and graduated with a GPA of 2.91, what is his residual? *(Please indicate whether the residual is positive or negative in your response, and **round to 2 decimal places**.)*

```{r}
2.91 - predictedgpa(1450)
```

### Question 4:

Calculate how much money a freshman has to spend to get 4 GPA

```{r}
# 4 = 2.84 + 0.04*x/100
((4-2.84)/0.04)*100
```

A freshman learned of this study and calculated that she would need to spend \$2,900 on textbooks to earn a 4.0 GPA. (You have just confirmed this calculation using the equation above). She decided to buy all of her textbooks new (rather than second-hand and cheaper) to help boost her GPA. Is she using the model in a statistically-sound way?

**Answer** : Of course not. No!

## Exercise 2:

For this exercise, we have Swedish Motor Insurance dataset, which was compiled by the Swedish Committee on the Analysis of Risk Premium in Motor Insurance. The data are cross-sectional, describing third party automobile insurance claims for the year 1977. The outcomes of interest are the number of claims (the frequency) and sum of payments (the severity), in Swedish kroners. Outcomes are based on 5 categories of distance driven by a vehicle, broken down by 7 geographic zones, 7 categories of recent driver claims experience and 9 types of automobile.

```{r}
# required libraries 
library(here)
library(fst)
library(tidyverse) 

# get the data 
motor_insurance <-read.csv(here("data", "SwedishMotorInsurance.csv"))
```

Let's look at the data first!

```{r}
str(motor_insurance)
# View(motor_insurance)
```

### Question 1:

Calculate adequate descriptive statistic for payment and claims in this data

**Means**:

```{r}
mean(motor_insurance$Claims)
mean(motor_insurance$Payment)
```

**correlations**

Check if there is a correlation with these two variables and plot it

```{r}
cor(motor_insurance$Claims, motor_insurance$Payment)

```

**plot**

```{r}
plot( motor_insurance$Claims, motor_insurance$Payment)

```

Let's now put a straight lines to our ploting of claims vs payments

```{r}
reg <- lm(Payment~Claims, data = motor_insurance)
plot( motor_insurance$Claims, motor_insurance$Payment)
abline(reg = reg, col="red")
```

```{r}
summary(reg)
```

Here, the straight line is defined by two things:

**intercept** : The y value at given x is zero.

**slope**: The amount of change in y when a unit of change happens in x

So, the following is our model (remember the funcitons and models)

**equation**: y= intercept + slope \* x

Thus, we can say that

payment = -3362 + 5020\*Claims

That is, every new claim results in 5020 SEK payment with an initial negative of 3362, which basically says if no claims there would be gain of 3362 for insurance companies. This model could be meaningful depending on the context. If the negative intercept makes sense in your context (i.e., the insurance company has other sources of income or factors that could lead to a gain even when there are no claims), then the model could be valid. However, if the negative intercept doesn’t make sense (i.e., it’s not possible for the insurance company to have a gain when there are no claims), you might want to reconsider the model.

## Exercise 3:

We have compiled the world record times for track events like the 100m dash and record distances for field events like the shotput into a single dataset.  This dataset includes information on the person who broke the record, his/her nationality, where the record was broken, and the year it was broken.  Note that not all world records are broken during the Olympics, with many occurring in regional or national competitions.

```{r}
wr <- read.csv(here("data", "worldrecord.csv"))
```

Let's start with eximing the data a bit

### Question 1:

How many different types of events (e.g. "Mens 100m," "Womens shotput," etc.) are represented in the dataset?

```{r}
# use table function for how many question
table(wr$Event)
```

```{r}
# or you can use count function in plyr package for better list
plyr::count(unique(wr$Event)) # instead of calling the packeag library(plyr) we used plyr::
```

### Question 2:

In what year did Usain Bolt first break the world record for the men's 100m dash?

```{r}
wr[wr$Athlete== "Usain Bolt",]
```

### Question 3:

Who was the first woman to break the women's 1 mile world record with a time of less than 260 seconds?

```{r}
wr[wr$Event=="Womens Mile",]
```

### Question 4:

Which variable tells us the record setting time or distance? What type of variable is this?

```{r}
str(wr)
```

### Question 5:

Which variable tells us when the record was broken? What type of variable is this?

```{r}
str(wr)
```

### Question 6:

For each sex, we will begin our analysis by generating a **scatterplot** of shotput distance and year. Why?

**Answer**: The scatterplot will show us if these two numeric variables are linearly related.

```{r}

# create a subset of mens shotput event
mensshotput <- wr[wr$Event=="Mens Shotput",]

# plot distance and year 
plot(mensshotput$Record, mensshotput$Year)

# create a subset of womens shotput event
womensshotput <- wr[wr$Event=="Womens Shotput",]
# plot distance and year 
plot(womensshotput$Record, womensshotput$Year)

```

### Question 7:

What will we be able to determine once we fit a **linear model** to this shotput world record data? and What is the equation for the linear model that predicts the World Record shotput distance for men?

```{r}
lm_mdl_men <- lm(Record~Year, data = mensshotput)
summary(lm_mdl_men)

# since year doesn't start with 0, recode 
mensshotput$Year <- mensshotput$Year - min(mensshotput$Year)
lm_mdl_men <- lm(Record~Year, data = mensshotput)
summary(lm_mdl_men)

# In the model, We will be able to report the average rate of change in world record shotput distance per year.
# the model now simply says that with an interceot of 17.90 every additional year effect the record 0.13 meter. 
```

### Question 9:

What is the dependent variable in our linear models?

**Answer**: Shotput distance

### Question 10:

How many records are in the menshot data frame?

```{r}
str(mensshotput)
```

### Question 11:

How many records are in the womenshot data frame?

```{r}
str(womensshotput)
```

### Question 12:

Is a linear model appropriate for the men's shotput data?

```{r}
# plot distance and year 
plot(mensshotput$Record, mensshotput$Year)
# plot distance and year 
plot(womensshotput$Record, womensshotput$Year)
```

### Question 13:

What can we say about the models for men and women?

```{r}
lm_mdl_women <- lm(Record~Year, data = womensshotput)
summary(lm_mdl_women)

# since year doesn't start with 0, recode 
womensshotput$Year <- womensshotput$Year - min(womensshotput$Year)
lm_mdl_women <- lm(Record~Year, data = womensshotput)
summary(lm_mdl_women)
```

It can be argued that given the slope of 0.23, The rate of change is greater for women than for men.

### Draw a conclusion

Based on scatterplots of the men's and women's world record shotput distance, both of these events follow a strong, **positive** linear relationship over time. The men's world record distance increases by an average of 0.13 meters per year, while the women's record distance increases by an average of 0.23 meters per year. Because the intercept estimate is the value of the record distance when **year** is equal to 0, it is not interpretable in the context of the problem. To correct this, we have **transpoze** the year variable by using the minimum year as 0. Both transpozed linear models fit the data well, with R-squared values for the men's and women's models equal to 17.9 and 14.83, respectively. Overall, the rate of change record per unit increase in year is greater for women than for men.

## Exercise 4

Keep on working with World Record Data set. Now, our **Reserach Questions** is "How have world record times for the men's and women's mile event changed over the years?"

Yet, let's start with some basic of linear regression!

### Question 1:

When fitting a model to data, what should you do **first** to examine the data?

**Answer**: Create a scatterplot of the two variables of interest. 

### Question 2:

When fitting a linear model, what will tell you the **proportion of variance** in the dependent variable that can be explained by the independent variable?

**Answer**: the R-squared value

### Question 3:

Which scatterplot shows a **stronger** linear relationship between World Record times in the Mile and Year:

```{r}
# create a subset of mens mile event
mensmile <- wr[wr$Event=="Mens Mile",]

# plot mile and year 
plot(mensmile$Record, mensmile$Year)

# create a subset of womens mile event
womensmile <- wr[wr$Event=="Womens Mile",]
# plot mile and year 
plot(womensmile$Record, womensmile$Year)
```

### Question 4:

On average, how many *seconds* do men trim off the world record time in the Mile each year? 

```{r}
men_mdl_mile <- lm(Record~Year, data = mensmile)
summary(men_mdl_mile)
```

### Question 5:

On average, how many *seconds* do women trim off the world record time in the Mile each year?

```{r}
women_mdl_mile <- lm(Record~Year, data = womensmile)
summary(women_mdl_mile)
```

### Question 6:

How many **years** would you predict it would take for the men's mile record to decrease by one full second? Use the model equation to help you answer the question.

```{r}
# model equation record = 1007.47 + (-0.393)*Year
1/0.393
```

### Question 7:

How many **years** would you predict it would take for the women's mile record to decrease by one full second? Use the model equation to help you answer the question.

```{r}
# model equation record = 2189.2 + (-0.972)*Year
1/0.972
```

### Question 8:

What proportion of variance in the men's and women's World Record times in the Mile can be explained by year? 

```         
Adjusted R-squared:  0.9767 # for men
Adjusted R-squared:  0.8861 # for women 
```

### Question 9:

Is the following is a reasonable conclusion to draw from this analysis?

World record times in the Mile have decreased linearly over the last several decades for both men and women.

**Answer**: YES! We can claim that World record times in the Mile have decreased linearly over the last several decades for both men and women.

### **Draw a conclusion**

Based on scatterplots of the men's and women's world record mile event, both of these events follow a strong, **negative** relationship over time. For both groups, the assumption of linearity appears to be satisﬁed. The men's world record mile time decreases by an average of 0.393 seconds per year, while the women's record distance decreases by an average of 0.976 seconds per year. Because the intercept estimate is the value of the record time when year is equal to 0, it is not interpretable in the context of the problem. Both linear models ﬁt the data well, with R-squared values for the men's and women's models equal to 0.976 and 0.886 , respectively. For the men's world record, 97.7% of the correct is explained by the linear model of year, while for the female world record, 88.6% of the correct in performance can be explained by the linear model of year.

## Exercise 4

Keep on working with World Record Data set. Now, **We want to find the best-fitting linear model for men's pole vault world records since 1970.**

To do that, first, let's create a new data frame that contains the world record cases in the men's pole vault event in years 1970 and later. 

```{r}
menspole <- wr[wr$Event=="Mens Polevault" & wr$Year>= 1970,]
```

### Question 1:

What is the standing world record height (in meters) for men's pole vault?

```{r}
max(menspole$Record)
```

### Question 2:

In what year did the pole vault record first exceed **6 meters**?

```{r}
menspole[menspole$Record>6,]
```

### Question 3:

Let's now Create a scatterplot showing the men's pole vault records since 1970 as a function of year. Fit a linear model to the data.

```{r}
men_mdl_pole <- lm(Record ~Year, data = menspole)
plot(menspole$Year, menspole$Record)
abline(reg = men_mdl_pole, col="red")
```

### Question 4:

Is the following best describes how the record has changed over time?

**The record pole vault height steadily increases over time.**

**Answer**: Yes, indeed, the record pole vault height steadily increases over time.

### Question 5:

Report the coefficient estimates for the linear model that describes the change in the men's pole vault world record since 1970

```{r}
summary(men_mdl_pole)
```

What is the intercept and slope?

intercept = 51.854

Slope = 0.0291

### Question 6:

What best describes how the men's pole vault world record has changed since 1970?

**Answer**: The record has increased by an average of 0.03 meters per year since 1970.

# Categorical Explanatory Variables

Categorical variables require special attention in regression analysis because, unlike dichotomous or continuous variables, they cannot by entered into the regression equation just as they are.  Instead, they need to be recoded into a series of variables which can then be entered into the regression model.  There are a variety of coding systems that can be used when recoding categorical variables.  Regardless of the coding system you choose, the overall effect of the categorical variable will remain the same. Ideally, you would choose a coding system that reflects the comparisons that you want to make.  For example, you may want to compare each level of the categorical variable to the lowest level (or any given level).  In that case you would use a system called **simple coding**.  Or you may want to compare each level to the next higher level, in which case you would want to use **repeated coding**.  By deliberately choosing a coding system, you can obtain comparisons that are most meaningful for testing your hypotheses. Below is a table listing various types of contrasts and the comparison that they make. **We should note that some forms of coding make more sense with ordinal categorical variables than with nominal categorical variables!**

![](images/Screenshot%202022-12-20%20at%2014.10.18.png)

## Exercise 1:

Let's get some data to work on categorical variable and regression! We have here a fish dataset, which records of 7 common different fish species in fish market sales. With this dataset, a predictive model can be performed using machine friendly data and estimate the weight of fish can be predicted.

```{r}
fish <- read.csv(here("data", "Fish.csv"))
str(fish)

```

For convenience, we have subset data for only four species!

```{r}
species <-c("Bream", "Perch", "Pike", "Roach")
fish <- fish[fish$Species==species,]
```

### Question 1:

Create a distribution plot for this dataset!

```{r}
barplot(table(fish$Species))
```

::: callout-tip
👋 A better way to visualize this could be using ggplot faceting options

```{r}
ggplot(data = fish, aes(x=Weight)) + 
  geom_histogram( bins = 9) +
  facet_wrap(~Species)
```
:::

### Question 2:

What are the basic descriptive metrics (mean)

```{r}
# in order to calculate means for each group we use aggregate() in base R
aggregate(fish$Weight, list(fish$Species), FUN=mean)
```

::: callout-tip
::: callout-tip
👋 A better way to visualize this could be using group_by() in dplyr pacakge

```{r}
fish |> 
  group_by(Species) |> 
  summarise(mean_wight = mean(Weight))
```
:::
:::

### Question 3:

Report the coefficient estimates for the linear model that describes the change in the weight for different fish species

```{r}
lm(formula = Weight~Species, data = fish)
```

### Question 4:

What is the problem with this model?

**Answer**: The problem with this model is that we have 4 spices and change in the weight of one of the species (Bream) has been repoted as intercept value, which is not correct. The model also has negative values for Persch and Roach, which is uninterpretable! Therefore, we have to set linear model with a zero intercept

```{r}
# with no intercept
lm(formula = Weight ~Species+0, data = fish)
```

Now, it is much more readable. We can say that according to our fish data, the predicted weights are 596, 372, 730, and 130 for bream, perch, pike, and roach species.

## Exercise 2

Regression lets you predict the values of a response variable from known values of explanatory variables. Which variable you use as the response variable depends on the question you are trying to answer, but in many datasets there will be an obvious choice for variables that would be interesting to predict. Over the next few exercises, you'll explore a Taiwan real estate dataset with 4 variables, which is a part of a market historical data set of real estate valuation collected from Sindian Dist., New Taipei City, Taiwan. The real estate valuation is the regression problem.

```{r}
taiwan_real_estate <- read.fst(here("data", "taiwan_real_estate.fst"))
str(taiwan_real_estate)
```

### Question 1:

Type `View(taiwan_real_estate)` in the console to view the dataset, and decide which variable would make a good response variable.

```{r}
View(taiwan_real_estate)
```

**Answer**: Predicting prices is a common business task, so house price makes a good response variable. So, price_twd_msq variable is one of the possible response variable for this dataset.

### Question 2:

Before you can run any statistical models, it's usually a good idea to visualize your dataset. Here, we'll look at the relationship between house price per area and the number of nearby convenience stores, using the Taiwan real estate dataset.

```{r}
plot(taiwan_real_estate$price_twd_msq, taiwan_real_estate$n_convenience)
```

👋 One challenge in this dataset is that the number of convenience stores contains integer data, causing points to overlap. To solve this, you will make the points transparent. This could be best done by using ggplot

```{r}
ggplot(data = taiwan_real_estate, aes(x=n_convenience, y= price_twd_msq))+
  geom_point(alpha=0.5)+
  geom_smooth(method="lm", se=FALSE) +
  scale_x_continuous("No. of convenience stores şn walking distance")+
  scale_y_continuous("House price per unit area in Taiqan dollars per square meter")+
  ggtitle("Taiwan Real Estate Price: Conveniency effects on Prices")+
  theme_bw()
```

### Question 3:

Linear regression models always fit a straight line to the data. Straight lines are defined by two properties: their intercept and their slope.

Here, you can see a scatter plot of house price per area versus number of nearby convenience stores, using the Taiwan real estate dataset.

Also run a linear regression with `price_twd_msq` as the response variable, `n_convenience` as the explanatory variable, and `taiwan_real_estate`as the dataset.

```{r}
taiwan_model <- lm(price_twd_msq~n_convenience, data = taiwan_real_estate)
plot(price_twd_msq~n_convenience, data = taiwan_real_estate)
abline(reg = taiwan_model, col="red")
```

### 

💡Remember that

The intercept is the y-value when x equals zero.

The slope is the rate of change in the y direction divided by the rate of change in the x direction.

```{r}
summary(taiwan_model)
```

### Question 4:

The model had an `(Intercept)` coefficient of `8.2242`. What does this mean?

**Answers:** On average, a house with zero convenience stores nearby had a price of 8.2242 TWD per square meter.

### Question 5:

The model had an `n_convenience` coefficient of `0.7981`. What does this mean?

**Answers:** If you increase the number of nearby convenience stores by one, then the expected increase in house price is `0.7981` TWD per square meter.

## Exercise 3

If the explanatory variable is categorical, the scatter plot that you used before to visualize the data doesn't make sense. Instead, a good option is to draw a barplot or histogram for each category.

The Taiwan real estate dataset has a categorical variable in the form of the age of each house. The ages have been split into 3 groups: 0 to 15 years, 15 to 30 years, and 30 to 45 years.

### Question 1:

Using `taiwan_real_estate`, plot a histogram of `price_twd_msq` 

```{r}
barplot(table(taiwan_real_estate$house_age_years))
```

👋 A better way of visualising would be the use of ggplot faceting option

```{r}
ggplot(data = taiwan_real_estate, aes(x=price_twd_msq))+
  geom_histogram(bins = 10) +
  facet_wrap(~house_age_years)
```

### Question 2:

Group `taiwan_real_estate` by `house_age_years`.

```{r}
table(taiwan_real_estate$house_age_years)
```

### Question 3:

Calculate the mean `price_twd_msq` for each group

```{r}
group1 <-taiwan_real_estate[taiwan_real_estate$house_age_years=="0 to 15",]
mean(group1$price_twd_msq, na.rm=TRUE)

group2 <-taiwan_real_estate[taiwan_real_estate$house_age_years=="15 to 30",]
mean(group2$price_twd_msq, na.rm=TRUE)

group3 <-taiwan_real_estate[taiwan_real_estate$house_age_years=="30 to 45",]
mean(group3$price_twd_msq, na.rm=TRUE)
```

👋 Much better and much easier way is to use dplyr group by and summarise functions

```{r}
taiwan_real_estate |> 
  group_by(house_age_years) |> 
  summarise(mean_by_group =mean(price_twd_msq))
```

### Question 4:

Run a linear regression with `price_twd_msq` as the response variable, `house_age_years` as the explanatory variable, and `taiwan_real_estate` as the dataset. Assign to `mdl_price_vs_age`.

```{r}
mdl_price_vs_age <- lm( price_twd_msq ~ house_age_years+0, data = taiwan_real_estate)
summary(mdl_price_vs_age)
```

## Draw a conlucion

We can argue that on average house prices in Taiwan has some correlations with the age of the house. 0-15 age houses are on average cost 12.635 , while 15 to 30 years cost 9.987. Interestingly, older than 30 years houses, even more expensive that middle age houses. This requires more attention, and why these houses are expensive. One explanation could be that these older houses are relatively larger than middle age and new houses, and size could be a better estimator in estimating houses prices in Taiwan real estate market.
